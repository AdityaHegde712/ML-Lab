{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "1. Use RAND to generate synthetic dataset\n",
    "2. Choose any ANN dataset kaggle or uci machine learning repository\n",
    "\n",
    "For both, \n",
    "1. Implement step-by-step for each with a standard set of weights etc\n",
    "2. Show tabular representation of hyperparameters as they are tuned at the end. Use CSVLogger code from earlier\n",
    "\n",
    "Note: <br>\n",
    "Decide activation functions as well, and define the neural network architecture <br>\n",
    "Define weights etc, create sub functions for forward and backward propagations <br>\n",
    "Set a number of iterations and run through the architectureÂ accordingly <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 13000\n",
    "n_features = 10\n",
    "n_classes = 2\n",
    "\n",
    "x_syn, y_syn = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative=6, n_redundant=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 10) <class 'tuple'>\n",
      "(13000,) <class 'tuple'>\n",
      "\n",
      "[[ 0.32109658 -3.55521745 -1.79901525  5.63529364 -2.88590423 -0.99211446\n",
      "  -0.82213901  3.08539582  1.79631095  0.69072372]\n",
      " [-2.85830434  0.94146699 -0.92897873  0.32050597  1.3548546  -0.58381635\n",
      "   0.40691861  2.15626725  0.88993014 -0.22135357]\n",
      " [-0.19986109  0.11897832  2.01723262  1.93974988 -1.13439803  2.56250543\n",
      "  -1.75773092 -0.7466832   0.96409535 -3.96289928]\n",
      " [-1.2977236   1.00513595  1.31864505  1.02653482 -1.06473218  1.42266209\n",
      "   1.71876769  0.69682981  0.29560212 -1.4690991 ]\n",
      " [ 0.55217032  1.26586226  2.16582174  0.3521321  -0.30993844  0.66955088\n",
      "   1.84639519  0.34162405 -0.71983337 -0.09763212]]\n",
      "[1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_syn.shape, type(x_syn.shape))\n",
    "print(y_syn.shape, type(y_syn.shape), end='\\n\\n')\n",
    "print(x_syn[:5])\n",
    "print(y_syn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "dry_bean_dataset = fetch_ucirepo(id=602) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "x_uci = dry_bean_dataset.data.features \n",
    "y_uci = dry_bean_dataset.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n",
      "0  28395    610.291       208.178117       173.888747     1.197191   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  \n",
      "   Class\n",
      "0  SEKER\n"
     ]
    }
   ],
   "source": [
    "print(x_uci[:1]) \n",
    "print(y_uci[:1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt: <br>\n",
    "Create code to define an ANN with functions for forward propagation, and backward propagation. It must be suited for a classification task, and the following specifications:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How I'll do this\n",
    "# Create constructor to initialize number of layers, learning rate, etc\n",
    "# Define sigmoid function\n",
    "# Define initial weights creator function based on x.shape's columns\n",
    "# Define ReLU function\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class my_ANN():\n",
    "    def __init__(self, learning_rate=0.001, n_hidden_layers=5, weights=None, random_state=42, output_dim=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.weights = weights\n",
    "        self.random_state = random_state\n",
    "        self.biases = np.random.uniform(size=(output_dim))\n",
    "    \n",
    "    def set_weights(self, x):\n",
    "        if self.weights == None:\n",
    "            self.weights = np.random.uniform(low=-0.01, high=0.01, size=(x.shape[1], 1))\n",
    "        return self.weights\n",
    "    \n",
    "    def train(self, x, y, epochs=30):\n",
    "        np.random.seed(42)\n",
    "        self.weights = self.set_weights(x)\n",
    "\n",
    "        for epoch in epochs:\n",
    "            # Forward propagation\n",
    "            inputs = np.array(x)\n",
    "            dot_prod = np.dot(inputs, self.weights) + self.biases\n",
    "            output = sigmoid(dot_prod)\n",
    "            error = y - output\n",
    "\n",
    "            # Backward propagation\n",
    "            del_output_error = error\n",
    "            del_dot_prod_error = der_sigmoid(output)\n",
    "            del_weights_error = np.dot(inputs.T, del_output_error * del_dot_prod_error)\n",
    "\n",
    "            self.weights += self.learning_rate * del_weights_error\n",
    "            self.biases += self.learning_rate * np.sum(del_output_error * del_dot_prod_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
