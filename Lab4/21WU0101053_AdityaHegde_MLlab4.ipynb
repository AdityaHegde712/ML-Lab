{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "1. Use RAND to generate synthetic dataset\n",
    "2. Choose any ANN dataset kaggle or uci machine learning repository\n",
    "\n",
    "For both, \n",
    "1. Implement step-by-step for each with a standard set of weights etc\n",
    "2. Show tabular representation of hyperparameters as they are tuned at the end. Use CSVLogger code from earlier\n",
    "\n",
    "Note: <br>\n",
    "Decide activation functions as well, and define the neural network architecture <br>\n",
    "Define weights etc, create sub functions for forward and backward propagations <br>\n",
    "Set a number of iterations and run through the architectureÂ accordingly <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class my_ANN():\n",
    "    def __init__(self, learning_rate=0.001, n_hidden_layers=5, weights=None, random_state=42, output_dim=1, neurons_per_layer=[10, 10, 1]):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.weights = weights\n",
    "        self.neurons_per_layer = neurons_per_layer\n",
    "        self.random_state = random_state\n",
    "        self.biases = np.random.uniform(size=(output_dim))\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def set_weights(self, x):\n",
    "        if self.weights is None:\n",
    "            inp_dim = x.shape[1]\n",
    "            self.weights = [np.random.uniform(low=-0.01, high=0.01, size=(inp_dim, self.neurons_per_layer[0]))]\n",
    "            for i in range(1, self.n_hidden_layers):\n",
    "                self.weights.append(np.random.uniform(low=-0.01, high=0.01, size=(self.neurons_per_layer[i - 1], self.neurons_per_layer[i])))  # Initialize weights for subsequent hidden layers\n",
    "        return self.weights\n",
    "    \n",
    "    def forward_propagation(self, x):\n",
    "        hidden_layers_output = [x]\n",
    "        \n",
    "        for i in range(self.n_hidden_layers):\n",
    "            dot_prod = np.dot(hidden_layers_output[-1], self.weights[i]) + self.biases\n",
    "            output = sigmoid(dot_prod)\n",
    "            hidden_layers_output.append(output)\n",
    "        \n",
    "        # final_output = hidden_layers_output[-1]\n",
    "        final_output = sigmoid(dot_prod)\n",
    "        return hidden_layers_output, final_output\n",
    "\n",
    "    def backward_propagation(self, x, y, hidden_layers_output):\n",
    "        del_weights = [None] * self.n_hidden_layers\n",
    "        \n",
    "        # Calculate error\n",
    "        error = y - hidden_layers_output[-1]\n",
    "\n",
    "        # Calculate deltas for each layer\n",
    "        del_output_error = error\n",
    "        for i in reversed(range(self.n_hidden_layers)):\n",
    "            del_dot_prod_error = der_sigmoid(hidden_layers_output[i + 1])\n",
    "            del_weights[i] = np.dot(hidden_layers_output[i].T, del_output_error * del_dot_prod_error)\n",
    "            del_output_error = np.dot(del_output_error, self.weights[i].T) * del_dot_prod_error\n",
    "\n",
    "        return del_weights, del_output_error\n",
    "    \n",
    "    def cross_entropy_loss(self, y, final_output):\n",
    "        # Calculate cross-entropy loss\n",
    "        epsilon = 1e-15  # Small value to prevent division by zero\n",
    "        final_output = np.clip(final_output, epsilon, 1 - epsilon)\n",
    "        loss = -np.mean(y * np.log(final_output) + (1 - y) * np.log(1 - final_output))\n",
    "        return loss\n",
    "\n",
    "    def train(self, x, y, epochs=30):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.weights = self.set_weights(x)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            # Forward propagation\n",
    "            hidden_layers_output, final_output = self.forward_propagation(x)\n",
    "            \n",
    "            # Calculate error\n",
    "            loss = self.cross_entropy_loss(y, final_output)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            # Backward propagation\n",
    "            del_weights, del_output_error = self.backward_propagation(x, y, hidden_layers_output)\n",
    "            \n",
    "            # Updating weights and bias\n",
    "            for i in range(self.n_hidden_layers):\n",
    "                self.weights[i] += self.learning_rate * del_weights[i]\n",
    "                self.biases[i] += self.learning_rate * np.sum(del_output_error * der_sigmoid(hidden_layers_output[i + 1], axis=0))\n",
    "\n",
    "            self.weights[-1] += self.learning_rate * np.dot(hidden_layers_output[-2].T, del_output_error * der_sigmoid(final_output))\n",
    "            self.biases[-1] += self.learning_rate * np.sum(del_output_error * der_sigmoid(final_output), axis=0)\n",
    "            \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over epochs')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Dataset ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 13000\n",
    "n_features = 10\n",
    "n_classes = 2\n",
    "\n",
    "x_syn, y_syn = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative=6, n_redundant=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 10) <class 'tuple'>\n",
      "(13000,) <class 'tuple'>\n",
      "\n",
      "[[ 0.32109658 -3.55521745 -1.79901525  5.63529364 -2.88590423 -0.99211446\n",
      "  -0.82213901  3.08539582  1.79631095  0.69072372]\n",
      " [-2.85830434  0.94146699 -0.92897873  0.32050597  1.3548546  -0.58381635\n",
      "   0.40691861  2.15626725  0.88993014 -0.22135357]\n",
      " [-0.19986109  0.11897832  2.01723262  1.93974988 -1.13439803  2.56250543\n",
      "  -1.75773092 -0.7466832   0.96409535 -3.96289928]\n",
      " [-1.2977236   1.00513595  1.31864505  1.02653482 -1.06473218  1.42266209\n",
      "   1.71876769  0.69682981  0.29560212 -1.4690991 ]\n",
      " [ 0.55217032  1.26586226  2.16582174  0.3521321  -0.30993844  0.66955088\n",
      "   1.84639519  0.34162405 -0.71983337 -0.09763212]]\n",
      "[1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_syn.shape, type(x_syn.shape))\n",
    "print(y_syn.shape, type(y_syn.shape), end='\\n\\n')\n",
    "print(x_syn[:5])\n",
    "print(y_syn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_syn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset doesn't need any preprocessing since it is synthetically created specifically for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10400,10400) and (1,10) not aligned: 10400 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hifia\\anaconda3\\envs\\MLlab\\Lab Activities\\Lab4\\21WU0101053_AdityaHegde_MLlab4.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(x_syn, y_syn, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ann \u001b[39m=\u001b[39m my_ANN(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, n_hidden_layers\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, neurons_per_layer\u001b[39m=\u001b[39m[\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ann\u001b[39m.\u001b[39;49mtrain(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m _, y_pred \u001b[39m=\u001b[39m ann\u001b[39m.\u001b[39mforward_propagation(x_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_pred \u001b[39m=\u001b[39m (y_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\hifia\\anaconda3\\envs\\MLlab\\Lab Activities\\Lab4\\21WU0101053_AdityaHegde_MLlab4.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_history\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# Backward propagation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m del_weights, del_output_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward_propagation(x, y, hidden_layers_output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# Updating weights and bias\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_hidden_layers):\n",
      "\u001b[1;32mc:\\Users\\hifia\\anaconda3\\envs\\MLlab\\Lab Activities\\Lab4\\21WU0101053_AdityaHegde_MLlab4.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     del_dot_prod_error \u001b[39m=\u001b[39m der_sigmoid(hidden_layers_output[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     del_weights[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(hidden_layers_output[i]\u001b[39m.\u001b[39mT, del_output_error \u001b[39m*\u001b[39m del_dot_prod_error)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     del_output_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(del_output_error, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[i]\u001b[39m.\u001b[39;49mT) \u001b[39m*\u001b[39m del_dot_prod_error\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hifia/anaconda3/envs/MLlab/Lab%20Activities/Lab4/21WU0101053_AdityaHegde_MLlab4.ipynb#X21sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m del_weights, del_output_error\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10400,10400) and (1,10) not aligned: 10400 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_syn, y_syn, test_size=0.2, random_state=42)\n",
    "ann = my_ANN(learning_rate=0.001, n_hidden_layers=3, neurons_per_layer=[10,10,1])\n",
    "\n",
    "ann.train(x_train, y_train, epochs=20)\n",
    "_, y_pred = ann.forward_propagation(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "dry_bean_dataset = fetch_ucirepo(id=602) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "x_uci = dry_bean_dataset.data.features \n",
    "y_uci = dry_bean_dataset.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13611, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_uci.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRatio  \\\n",
      "0  28395    610.291       208.178117       173.888747     1.197191   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  Roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  \n",
      "   Class\n",
      "0  SEKER\n"
     ]
    }
   ],
   "source": [
    "print(x_uci[:1]) \n",
    "print(y_uci[:1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
